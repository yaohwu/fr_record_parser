# v2

## 数据描述

近800的用户，对于1300个模板在17年4月到11月，8个月内的预览记录。

## 依据个人历史记录预测

两种思路，一种是时序推荐，一种是基于某种逻辑直接进行普通推荐。

容易陷入局部最优解

### 时序推荐

### 普通推荐

普通推荐，非常简单，就是基于历史预览策略进行推荐。
思路就是把个人的预览历史中的模板，生成一个针对个人的热度排行。完全不依赖别的用户，只从自身的历史预览记录中提取。



## 基于用户的协同过滤推荐

在 v1 中也提到过了，主要是进行优化。
进行优化的部分：

1. 优化用户对模板的兴趣程度的算法
2. 分为测试集和训练集，防止过度拟合
3. 优化相似度的计算

### 优化兴趣程度算法

测试发现，去除遗忘因子的影响，计算用户相似度甚至更准确，可能是之前对于遗忘因子的模拟不准确。
去除遗忘因子。

### 分测试集和训练集

分测试集和训练集的目的只是为了防止过度拟合，而我们的数据是时序的数据，因此只要比较预测不同时间的模型评分就可以判断出是否有严重的过度拟合现象。

### 相似度的计算

#### [皮尔逊相关系数](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)

v1 中使用的就是，不再多做介绍

#### [Jaccard相似度](https://en.wikipedia.org/wiki/Jaccard_index)

简介，可见wiki。

```python3
    if a != 0 or b != 0:
        union += 1
        if a != 0 and b != 0:
            intersect += 1
```

```shell
data cf
pearson:

[(333, 0.5906341355087884), (386, 0.5397226254363309), (574, 0.4860351668574924), (534, 0.4258154171719675), (142, 0.41818254166450153), (151, 0.41356746741880185)]
[(83, 1.5517499011974871), (14, 1.5212183991676231), (126, 1.231347601412861), (41, 1.016597767097507), (72, 0.9981374701147083)]
p: 0.4  r: 0.16666666666666666 f1: 0.23529411764705882
jaccard:

[(333, 0.3888888888888889), (386, 0.35384615384615387), (574, 0.33962264150943394), (534, 0.2962962962962963), (449, 0.2857142857142857), (643, 0.2553191489361702)]
[(83, 1.5510900862968309), (14, 1.3871814968563265), (126, 1.0499675265632715), (41, 0.9930734772163918), (72, 0.8714929301039298)]
p: 0.4  r: 0.16666666666666666 f1: 0.23529411764705882
```

实验的结果差不多，都并不是十分理想。

当使用前30天的数据，预测接下来5天的预览模板时：随着k值的变化，准确率和召回率如图。

![myplot.png](myplot.png)

可见，当k取的时候，效果是最好的。

## 算法加权取结果
